ğŸ§  Cross-Platform RAG System Powered by Pinecone
A Retrieval-Augmented Generation (RAG) system designed to handle user queries from multiple channels (WhatsApp, Slack, Telegram) and provide accurate, context-aware responses using OpenAI + Pinecone-powered knowledge base.

ğŸš€ Features
ğŸ§µ Multi-Channel Query Handling
Accepts questions from:

WhatsApp

Slack

Telegram

Uses a shared channel handler to normalize messages

ğŸ” Retrieval-Augmented Generation (RAG)
AI Agent queries Pinecone Vector Store for relevant context

Performs semantic search via OpenAI Embeddings

Responds with highly relevant and accurate information

ğŸ“š Knowledge Base Creation
Uploads knowledge via PDF form submission

Extracts text and splits into chunks (Recursive Character Text Splitter)

Embeds and stores data in Pinecone

ğŸ”„ Context Routing
Dynamically switches response format based on trigger source

Sends results back through WhatsApp, Slack, or Telegram

âš™ï¸ Architecture Overview
plaintext
Copy
Edit
ğŸ“¥ Incoming Query (WhatsApp/Slack/Telegram)
        â†“
ğŸ§­ Channel Normalizer
        â†“
ğŸ§  AI Agent
   â†³ ğŸ” Vector Retrieval via Pinecone
   â†³ ğŸ§¾ Embedding via OpenAI
        â†“
ğŸ—£ Formulate Answer
        â†“
ğŸ“¤ Return to User on Original Platform
ğŸ§© Components
Module	Description
WhatsApp/Slack/Telegram Triggers	Event-based listeners for incoming messages
Channel Normalizer	Standardizes message handling
AI Agent	Main logic, reasoning, and response generation
Pinecone Vector Store	Stores embedded knowledge chunks
OpenAI Embeddings	Converts text to vectors for semantic search
Knowledge Base Builder	Form submission â†’ PDF extraction â†’ vector store
Response Dispatcher	Sends responses back to correct channel

ğŸ—‚ Knowledge Base Workflow
User Submits a Form (with PDF)

Text Extracted from PDF

Chunking with Recursive Text Splitter

Embedding with OpenAI API

Storage in Pinecone Vector DB

ğŸ§ª AI Agent Behavior
Embedding comparison for document retrieval

Hybrid search using Pinecone + AI completion

Option to use multiple OpenAI models (e.g., GPT-3.5, GPT-4)

Supports query context switching between Vector Store Tools

ğŸ“¦ Technologies Used
ğŸ§  OpenAI Chat Models

ğŸ“Š Pinecone Vector Store

ğŸ§® OpenAI Embedding API

ğŸ’¬ WhatsApp Business API

ğŸ›  Slack & Telegram Bot APIs

ğŸ“„ PDF Text Extractor

ğŸ” Recursive Character Text Splitter

ğŸ›  Use Cases
Enterprise FAQ bots across platforms

Internal documentation query systems

Context-aware customer support agents

RAG-powered Slackbots or WhatsApp assistants

ğŸ“¬ Get Started
Configure Channel APIs (WhatsApp, Slack, Telegram)

Set up Pinecone account and vector store

Add OpenAI API keys

Deploy the form handler to build your KB

Start your agent and begin chatting!